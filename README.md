# ğŸš€ DASHRAG-HACKATHON  

![Python](https://img.shields.io/badge/Python-3.11+-blue?logo=python)  
![Django](https://img.shields.io/badge/Django-5.0-green?logo=django)  
![Docker](https://img.shields.io/badge/Docker-Compose-blue?logo=docker)  
![LLMs](https://img.shields.io/badge/LLM-Groq%20%7C%20OpenAI%20%7C%20HF%20%7C%20Ollama-orange?logo=openai)  

ğŸ” **Ask questions in plain English â†’ Get SQL queries â†’ See results instantly**  

---

## âœ¨ Features  

- ğŸ¤– **Natural Language â†’ SQL** using Groq, OpenAI, HuggingFace, or Ollama  
- ğŸ“š **Schema-aware RAG** powered by FAISS for grounded SQL generation  
- ğŸ—„ï¸ **SQLite or Postgres (configurable)** â€“ SQLite is default in Docker  
- ğŸ“Š **Interactive Dashboard** to explore results & visualizations  
- ğŸ³ **Dockerized setup** with auto-migrations, staticfiles, and optional demo seeding  

---

## ğŸ“‚ Project Structure  

```bash
hackathon_ai_dashboard/
â”œâ”€â”€ manage.py
â”œâ”€â”€ hackathon_ai_dashboard/        # Django settings & project config
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ models.py                  # User, Ticket, Bet models
â”‚   â”œâ”€â”€ views.py                   # Dashboard view
â”‚   â”œâ”€â”€ process.py                 # NL â†’ SQL pipeline
â”‚   â”œâ”€â”€ llm_loader.py              # Provider switcher
â”‚   â”œâ”€â”€ query_generator.py         # LLM prompting logic
â”‚   â”œâ”€â”€ management/commands/       # custom mgmt commands (e.g. seed_demo)
â”‚   â””â”€â”€ templates/dashboard.html   # UI template
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ entrypoint.sh
â”œâ”€â”€ gunicorn.conf.py
â””â”€â”€ requirements.txt
```

---

## âš™ï¸ How It Works  

```mermaid
flowchart TD
    A[User Question] --> B[LLM Prompt + Schema Index]
    B --> C[SQL Query Generated]
    C --> D[SQL Execution on DB]
    D --> E[Results Returned]
    E --> F[Dashboard UI + Visualization]
```

---

## ğŸš€ Running with Docker  

### ğŸ”‘ Prerequisites  
- Docker  
- Docker Compose v1.22+  

### ğŸ“¥ Setup & Run  

```bash
# Build and start containers
docker-compose up --build
```

Open the app â†’ [http://localhost:8000/dashboard](http://localhost:8000/dashboard)

---

## ğŸ› ï¸ Environment Variables  

Create a `.env` file in the project root (same dir as docker-compose.yml):

```ini
SECRET_KEY=change-me
DEBUG=true

# Optional: auto-seed demo data
DEMO_SEED=true
DEMO_SEED_COUNT=10000

# LLM Providers (set one or more)
GROQ_API_KEY=your_groq_key
OPENAI_API_KEY=your_openai_key
HUGGINGFACEHUB_API_TOKEN=your_hf_key
```

---

## ğŸ§  Switching LLM Provider  

Edit **`core/llm_loader.py`**:  

```python
model_type = "groq"      # or "openai" | "huggingface" | "ollama"
model_name = "llama3-70b-8192"
```

---

## ğŸ§ª Demo Seeding  

We use **best practice seeding**:  
- `core/migrations/0002_seed_defaults.py` â†’ minimal defaults, runs once.  
- `python manage.py seed_demo --count 10000` â†’ bulk/demo seed (idempotent).  

In Docker, seeding runs automatically if you set:  

```ini
DEMO_SEED=true
DEMO_SEED_COUNT=10000
```

and the DB is empty.

---

## ğŸ›¡ï¸ Security Notes  

- âš ï¸ Only allow **SELECT queries** in production to avoid risky SQL execution.  
- Use proper `.env` secrets (never hardcode API keys).  
- For production, set `DEBUG=False` and generate a strong `SECRET_KEY`.  

---

## ğŸ› ï¸ Deployment Notes  

- Default Docker setup uses **SQLite** (mounted volume).  
- For production, update `settings.py` + `docker-compose.yml` to use **Postgres**.  
- Gunicorn is used as the WSGI server (configured via `gunicorn.conf.py`).  

---

## ğŸ“œ License  

MIT / Apache 2.0 (choose your license)  

## Video description
https://drive.google.com/file/d/1vYvjM0AFIEJFwLUVYLCjMDeOrMIyPs0m/view?usp=sharing


## Example prompt that you can use
Show me top 10 users by win amount
Show me yesterdayâ€™s revenue by provider
Show me top 10 players by net revenue last week
Show all users and revenue generated by them
Show top 10 users by loss
